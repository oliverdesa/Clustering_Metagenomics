{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from functions import *\n",
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzymes = ['dl_endopeptidase', 'ld_carboxypeptidase', \n",
    "               'ld_endopeptidase', 'amidase',\n",
    "               'dd_carboxypeptidase', 'diadenylate_cyclase',\n",
    "               'muramidase', 'glucosaminidase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/clustering/cluster_maps/dl_endopeptidases.tsv',sep='\\t')\n",
    "\n",
    "df = df.iloc[:, 1:4]\n",
    "\n",
    "df = df[pd.isna(df[df.columns[2]])]\n",
    "\n",
    "grouped = df.groupby('dl_endopeptidases-mmseqs_cluster')['dl_endopeptidases-unclustered'].apply(list).reset_index(name='unclustered_list')\n",
    "\n",
    "display(grouped, len(grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A0A078MK14'], ['A0A1A6AKX1'], ['A0A2U3N4J8'], ['A0A8A0RIX7'], ['A0A8D3WV90'], ['A0A8D3WY21'], ['A0A8F5H2Q7', 'A0A098EI80'], ['A0A8G2HRI5'], ['A0A8J2ZPT7'], ['A0A8S0GDS2'], ['A0A8S0GPC8'], ['A0A8S0YF99'], ['A0A916BQR8', 'A0A1V5WBM4'], ['A0A916CW89'], ['A0A916HNI5'], ['A0A916IAR6'], ['A0A916JZY9', 'W8ZK78', 'A0A919ZDK0'], ['A0A916KA10'], ['A0A916NI20'], ['A0A917ET50', 'I0JQV7'], ['A0A919WN25'], ['A0A926E6B6', 'A0A316LKK8'], ['A0A926HT18', 'J0MY21', 'A0A928K2M9', 'A0A928KYG8', 'A0A6S6XCB1', 'A0A7C7AQD7'], ['A0A927LH80'], ['A0A928LPM8', 'A0A413G4S5', 'A0A926IJ38', 'A0A498CNA2', 'A0A845RI86', 'A0A845SXI2', 'A0A3A9IJD7', 'A0A1Y4MUN7', 'A0A3C1LY33', 'A0A3B9VTI7', 'A0A6N2V297', 'A0A3D0NTZ4', 'A7VT68', 'A0A1C5YFQ8', 'A0A3A9GL57', 'A0A928K5J0', 'A0A143ZRA8', 'A0A1C5LK98', 'A0A1H8CKK5', 'A0A926I4N9', 'A0A926EA13'], ['A0A928NUY4', 'A0A928F840', 'R5PSZ8', 'A0A356GGC1'], ['A0A928PTA1', 'A0A3D5TKR5', 'A0A970U5P3'], ['A0A940NV69', 'A0A3B8NYU2'], ['A0A940ZKM3'], ['A0A942PKR4'], ['A0A949RNE6'], ['A0A970N7P1', 'A0A970FUE6', 'A0A357WRL2', 'A0A316P6S0'], ['A0A971NJL2'], ['A0A977II70', 'A0A1Y2MSQ6'], ['R7ITK9', 'R6YTV6', 'R7GGL2'], ['UPI0001CF73DB'], ['UPI001BDB9821', 'A0A8G0TN23', 'UPI0004649A92', 'UPI0009F7343A', 'UPI001293C30E', 'UPI0022807482', 'A0A8G0WK54', 'UPI0004679F71', 'UPI000ACC93C1', 'UPI00137484FB', 'UPI002280A9D8', 'A0A6A8FPK7', 'UPI000493F016', 'UPI000B3E49FD', 'UPI0013783F42', 'UPI002280E66F', 'UPI0004946308', 'UPI000B42DF4B', 'UPI0013BA2BEA', 'UPI0022814A49', 'A0A6H0WSD3', 'UPI00049F76D6', 'UPI000B443AAC', 'UPI0013D00892', 'UPI0022815E9D', 'A0A6H2JVI1', 'UPI0004CFD86E', 'UPI000B52EECE', 'UPI0013D16301', 'UPI0022818CAC', 'UPI000516E55C', 'UPI000BA8553F', 'UPI00178CAB6D', 'UPI0022820454', 'UPI00056F566C', 'UPI000C77A590', 'UPI0022820F59', 'UPI000589D2F9', 'UPI000C9EEC13', 'UPI001BDB9C6D', 'UPI0022821518', 'UPI0005974F89', 'UPI000CD09DF8', 'UPI001BDBA3BA', 'UPI0022826123', 'UPI00059DF5E3', 'UPI000CDA6085', 'UPI001BDBAE37', 'UPI002282704F', 'A0A164YHE1', 'UPI0005A13DEE', 'UPI000CDA693A', 'UPI001CDCD0C5', 'UPI0022827E05', 'D9I2X1', 'UPI0005A4B94F', 'UPI000D777A7F', 'UPI001E554A75', 'UPI0022829E52', 'E0U4Y9', 'UPI0005B669D6', 'UPI000E2F7ABF', 'UPI001E633981', 'UPI0022AA0C16', 'UPI0005C79CE7', 'UPI000E721E70', 'UPI001EE09278', 'G4P1I6', 'UPI00065D4A9B', 'UPI000E7329F2', 'UPI001FD8A655', 'UPI000670C5C7', 'UPI000F096D61', 'UPI00202A5E4F', 'UPI000683E4AC', 'UPI000F48C209', 'UPI00202AEE24', 'UPI00069FAEAB', 'UPI000F5261DA', 'UPI00202B276E', 'UPI0006A80776', 'UPI000F5290EB', 'UPI00203FE57C', 'UPI000745D6BE', 'UPI000F543356', 'UPI0020B33D17', 'M4KWM6', 'UPI00086B51F1', 'UPI000F63D0B6', 'UPI0020B42058', 'UPI00089E02E9', 'UPI0010099A0F', 'UPI002116E6B1', 'UPI000932BB62', 'UPI00103AB842', 'UPI0021C84FAB', 'UPI000932DB22', 'UPI00105F0AE2', 'UPI00227D9AB6', 'UPI0009529A1A', 'UPI0010634B49', 'UPI00227E2780', 'P96740', 'UPI000970A346', 'UPI001066ADF0', 'UPI00227E3695', 'UPI0009B305BC', 'UPI001150F02D', 'UPI00227ECBD2', 'A0A8D5WFY9', 'UPI0009B51D35', 'UPI0011A078B2', 'UPI00227F6679', 'UPI0009B547DC', 'UPI0011C9B9A7', 'UPI00228023C3', 'A0A8F7SM63', 'UPI00022BB1F2', 'UPI0009B5599B', 'UPI0011DCA035', 'UPI002280504B', 'A0A8F9X3R1', 'UPI0002A14634', 'UPI0009F5A88F', 'UPI0011E8E255', 'UPI00228070D2', 'E9NPA6', 'I2HW05', 'A0A7W4LV96', 'A0A4V7TTP2', 'S6FKS7', 'A0A8B5YHC2', 'A0A6C1VQR4', 'A0A7Z1B5S4', 'M5NZY7', 'A0A1C3SKD6', 'Q0KG20', 'A0A8D4BIG3', 'A0A0B6AVY6', 'A0A806UC77', 'A0A5C0WI84', 'A0A498U217', 'M5RJH3']]\n"
     ]
    }
   ],
   "source": [
    "to_download = grouped['unclustered_list'].tolist()\n",
    "\n",
    "print(to_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_check(ids, output_dir, replacements):\n",
    "    replacement_found = False  # Flag to track if a replacement is found\n",
    "\n",
    "    for id in ids:\n",
    "        url = f\"https://alphafold.ebi.ac.uk/files/AF-{id}-F1-model_v4.pdb\"\n",
    "        pdb_file_path = os.path.join(output_dir, f\"AF-{id}-F1-model_v4.pdb\")\n",
    "\n",
    "        # Download the file\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(pdb_file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "\n",
    "            # Check if \"NoSuchKey\" is in the file\n",
    "            with open(pdb_file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                if \"NoSuchKey\" in content:\n",
    "                    os.remove(pdb_file_path)  # Delete the file if the string is found\n",
    "                else:\n",
    "                    replacements.append(id)\n",
    "                    replacement_found = True\n",
    "                    break  # Exit the loop if the string is not found\n",
    "\n",
    "    if not replacement_found:\n",
    "        replacements.append('None')  # Append None if no replacement was found\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the output files\n",
    "output_dir = \"C:/Users/odesa/Desktop/PDB_test/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over each list of IDs\n",
    "replacements = []\n",
    "for id_list in to_download:\n",
    "    download_and_check(id_list, output_dir, replacements)\n",
    "    # The function will stop processing the current list if \"NoSuchKey\" is not found in any file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0A078MK14', 'None', 'None', 'None', 'None', 'None', 'A0A098EI80', 'None', 'None', 'None', 'None', 'None', 'A0A1V5WBM4', 'None', 'None', 'None', 'W8ZK78', 'None', 'None', 'I0JQV7', 'None', 'A0A316LKK8', 'J0MY21', 'None', 'A0A413G4S5', 'R5PSZ8', 'A0A3D5TKR5', 'A0A3B8NYU2', 'None', 'None', 'None', 'A0A357WRL2', 'None', 'A0A1Y2MSQ6', 'R6YTV6', 'None', 'A0A6A8FPK7']\n"
     ]
    }
   ],
   "source": [
    "print(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped['unclustered_list'] = replacements\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('../../data/clustering/cluster_maps/dl_endopeptidases.tsv',sep='\\t')\n",
    "\n",
    "df = df.iloc[:, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(original, grouped, on='dl_endopeptidases-mmseqs_cluster', how='left')\n",
    "\n",
    "original['replacements'] = merged_df['unclustered_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "original['dl_endopeptidases-mmseqs_cluster'] = np.where(original['replacements'].notna(), \n",
    "                                                        original['replacements'], original['dl_endopeptidases-mmseqs_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe based on the condition\n",
    "filtered_df = grouped[grouped['unclustered_list'] == 'None']\n",
    "\n",
    "# Get the values from the 'dl_endopeptidases-mmseqs_cluster' column\n",
    "values = filtered_df['dl_endopeptidases-mmseqs_cluster'].values\n",
    "\n",
    "# Create a text file and write the values to it\n",
    "with open('E:/PDBs/dl_endopeptidases_representatives/to_delete.txt', 'w') as file:\n",
    "    for value in values:\n",
    "        file.write(str(value) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be made into a function and optimized. Shoul dimplement multiprocessing for\n",
    "# downloading the PDBs and checking if they are empty\n",
    "\n",
    "\n",
    "enzymes = ['dl_endopeptidase', 'ld_carboxypeptidase', \n",
    "               'ld_endopeptidase', 'amidase',\n",
    "               'dd_carboxypeptidase', 'diadenylate_cyclase',\n",
    "               'muramidase', 'glucosaminidase']\n",
    "\n",
    "for enzyme in enzymes:\n",
    "    \n",
    "    # read in the cluster map, drop the first column\n",
    "    df = pd.read_csv('../../data/clustering/cluster_maps/' + enzyme + 's.tsv',sep='\\t')\n",
    "    df = df.iloc[:, 1:4]\n",
    "\n",
    "    # drop the rows where the foldseek cluster is not empty\n",
    "    no_foldseek = df[pd.isna(df[df.columns[2]])]\n",
    "\n",
    "    # group by the mmseqs cluster and create a list of the unclustered ids\n",
    "    grouped = no_foldseek.groupby(f'{enzyme}s-mmseqs_cluster')[f'{enzyme}s-unclustered'].apply(list).reset_index(name='unclustered_list')\n",
    "\n",
    "    # create a directory for the PDB files\n",
    "    to_download = grouped['unclustered_list'].tolist()\n",
    "    output_dir = f\"C:/Users/odesa/Desktop/PDB_test/{enzyme}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop over each list of IDs\n",
    "    replacements = []\n",
    "    for id_list in to_download:\n",
    "        # download new PDBs, check if empty, creating a list of replacements\n",
    "        download_and_check(id_list, output_dir, replacements)\n",
    "\n",
    "    # Replace the 'unclustered_list' column with the list of replacements\n",
    "    grouped['unclustered_list'] = replacements\n",
    "\n",
    "    # Merge the original dataframe with the new one on mmseqs cluster\n",
    "    merged_df = pd.merge(df, grouped, on=f'{enzyme}s-mmseqs_cluster', how='left')\n",
    "\n",
    "    # Create a new column with the list of replacements\n",
    "    df['replacements'] = merged_df['unclustered_list']\n",
    "\n",
    "    # Replace the mmseqs cluster with the list of replacements if it is not empty\n",
    "    df[f'{enzyme}s-mmseqs_cluster'] = np.where(df['replacements'].notna(), \n",
    "                                                df['replacements'], \n",
    "                                                df[f'{enzyme}s-mmseqs_cluster'])\n",
    "\n",
    "    # Filter the dataframe based on the condition\n",
    "    filtered_df = grouped[grouped['unclustered_list'] == 'None']\n",
    "\n",
    "    # Get the values from the 'dl_endopeptidases-mmseqs_cluster' column\n",
    "    values = filtered_df[f'{enzyme}s-mmseqs_cluster'].values \n",
    "\n",
    "    # Create a text file and write the values to it\n",
    "    with open(f'C:/Users/odesa/Desktop/PDB_test/{enzyme}/to_delete.txt', 'w') as file:\n",
    "        for value in values:\n",
    "            file.write(str(value) + '\\n')\n",
    "\n",
    "    df.to_csv(f'C:/Users/odesa/Desktop/{enzyme}_cluster_update.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for enzyme in enzymes:\n",
    "    df = pd.read_csv(f'C:/Users/odesa/Desktop/{enzyme}_cluster_update.tsv', sep='\\t')\n",
    "\n",
    "    # df[f'{enzyme}s-mmseqs_cluster'] = df.apply(lambda row: row[f'{enzyme}s-unclustered'] if pd.isna(row[f'{enzyme}s-mmseqs_cluster']) else row[f'{enzyme}s-mmseqs_cluster'], axis=1)\n",
    "    \n",
    "    # df.to_csv(f'C:/Users/odesa/Desktop/{enzyme}_cluster_update.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    unique_values = df[f'{enzyme}s-mmseqs_cluster'].unique().tolist()\n",
    "\n",
    "    downloaded = []\n",
    "    with open(f'E:/PDBs/{enzyme}s_representatives/all_files.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            downloaded.append(line.strip())\n",
    "\n",
    "    to_remove = [x for x in downloaded if x not in unique_values]\n",
    "    print(f'{enzyme}: {len(to_remove)} {to_remove}')\n",
    "\n",
    "    with open(f'E:/PDBs/{enzyme}s_representatives/to_remove.txt', 'w') as file:\n",
    "        for value in to_remove:\n",
    "            file.write(str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzymes = ['dl_endopeptidase', 'ld_carboxypeptidase', \n",
    "               'ld_endopeptidase', 'amidase',\n",
    "               'dd_carboxypeptidase', 'diadenylate_cyclase',\n",
    "               'muramidase', 'glucosaminidase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldseek_path = '/media/oliver/PGH_Backup/clustering/new_foldseek/'\n",
    "mmseqs_path = '/media/oliver/PGH_Backup/clustering/maps/'\n",
    "\n",
    "for enzyme in enzymes:\n",
    "    df = pd.read_csv(f'{mmseqs_path}{enzyme}_cluster_update.tsv', sep='\\t')\n",
    "    # print(df.head())\n",
    "    df = df.iloc[:, 0:2]\n",
    "    # print(df.head())\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    \n",
    "    df.to_csv(f'{mmseqs_path}{enzyme}_cluster_no_foldseek.tsv', sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldseek_path = '/media/oliver/PGH_Backup/clustering/new_foldseek/'\n",
    "mmseqs_path = '/media/oliver/PGH_Backup/clustering/maps/'\n",
    "\n",
    "for enzyme in enzymes:\n",
    "    create_maps(f'{mmseqs_path}{enzyme}_cluster_no_foldseek.tsv', f'{foldseek_path}{enzyme}/foldseek_result_{enzyme}_cluster.tsv', f'{enzyme}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = []\n",
    "\n",
    "for enzyme in enzymes:\n",
    "    df = pd.read_csv(f'../../data/clustering/cluster_maps/{enzyme}.tsv', sep='\\t')\n",
    "    \n",
    "    print(f\"Original DataFrame shape for {enzyme}: {df.shape}\")\n",
    "\n",
    "    # Get the counts of each value in the target column\n",
    "    value_counts = df.iloc[:, 3].value_counts()\n",
    "\n",
    "    # Identify the values that occur only once\n",
    "    single_occurrence_values = value_counts[value_counts == 1].index\n",
    "\n",
    "    # Drop rows where the column value is one of those that occur only once\n",
    "    df = df[~df.iloc[:, 3].isin(single_occurrence_values)]\n",
    "\n",
    "    df.to_csv(f'../../data/clustering/cluster_maps/{enzyme}.tsv', sep='\\t', index=False)\n",
    "\n",
    "    print(f\"Modified DataFrame shape for {enzyme}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_maps('/Volumes/PGH-Backup/foldseek/dd_endopeptidases_clusters.tsv', '/Volumes/PGH-Backup/foldseek/foldseek_result/foldseek_result_cluster.tsv', 'dd_endopeptidase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_2092/2862087956.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_10_columns = pd.read_csv('../../data/clustering/cluster_maps/combined_clusters.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "# Read the TSV files into DataFrames\n",
    "df_10_columns = pd.read_csv('../../data/clustering/cluster_maps/combined_clusters.tsv', sep='\\t')\n",
    "df_3_columns = pd.read_csv('../../data/clustering/cluster_maps/dd_endopeptidase.tsv', sep='\\t')\n",
    "\n",
    "# Concatenate the DataFrames along the columns\n",
    "combined_df = pd.concat([df_10_columns, df_3_columns], axis=1)\n",
    "\n",
    "# print(combined_df.columns)\n",
    "\n",
    "# drop the column called Unnamed: 0\n",
    "\n",
    "combined_df = combined_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# print(combined_df.columns)\n",
    "\n",
    "# Save the combined DataFrame to a TSV file\n",
    "combined_df.to_csv('../../data/clustering/cluster_maps/combined_clusters.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
