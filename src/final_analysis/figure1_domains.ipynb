{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load tables\n",
    "\n",
    "domain_table = pd.read_csv('/Volumes/PGH-Backup/domains/IPS/all_IPS_results.tsv', sep='\\t', header=None)\n",
    "\n",
    "display(domain_table, domain_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the enzyme name and aggregate the domain column as a list\n",
    "grouped_df = domain_table.groupby(0)[5].apply(list).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_clean = grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_clean[0] = grouped_df_clean[0].str.split('|').str[0]\n",
    "\n",
    "display(grouped_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_clean.to_csv('/Volumes/PGH-Backup/domains/IPS/all_IPS_results_grouped.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Merging with cluster table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temporary swap to a windows enviorment, paths changed accordingly\n",
    "# grouped_df_clean = pd.read_csv(\"E:\\\\domains\\\\IPS\\\\all_IPS_results_grouped.tsv\", sep='\\t', header=None)\n",
    "grouped_df_clean = pd.read_csv(\"/Volumes/PGH-Backup/domains/IPS/all_IPS_results_grouped.tsv\", sep='\\t', header=None)\n",
    "\n",
    "display(grouped_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_domain_table(df):\n",
    "    \"\"\"\n",
    "    Function to format the domain table for future use\n",
    "    \"\"\"\n",
    "    # Rename columns\n",
    "    df.rename(columns={0: 'FullIdentifier', 1: 'Domains'}, inplace=True)\n",
    "    \n",
    "    # Split the FullIdentifier column into separate columns\n",
    "    df['Uniref'] = df['FullIdentifier'].str.split('_').str[2]\n",
    "\n",
    "    df['Enzyme'] = df['FullIdentifier'].str.split('_').str[0]\n",
    "\n",
    "    df.drop_duplicates(subset='Uniref', inplace=True)\n",
    "\n",
    "    enzymes = df['Enzyme'].unique()\n",
    "\n",
    "    return df, enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cluster map\n",
    "# cluster_map = pd.read_csv(\"E:\\\\clustering\\\\newest_cluster_maps\\\\catted_maps.tsv\", sep='\\t', index_col=0, header=None)\n",
    "cluster_map = pd.read_csv(\"/Volumes/PGH-Backup/clustering/newest_cluster_maps/catted_maps.tsv\", sep='\\t', index_col=0, header=None)\n",
    "\n",
    "display(cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cluster_map(df):\n",
    "    \"\"\"\n",
    "    Function to format the cluster map for future use, return list of unique enzymes\n",
    "    \"\"\"\n",
    "    # Rename columns\n",
    "    df.rename(columns={1: 'unclustered', 2: 'mmseqs', 3: 'foldseek'}, inplace=True)\n",
    "\n",
    "    df.drop_duplicates(subset='unclustered', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert(domain_string):\n",
    "    domain_string = [ast.literal_eval(x) for x in domain_string]\n",
    "    \n",
    "    domain_string = [\n",
    "        item\n",
    "        for sublist in domain_string\n",
    "        for item in sublist\n",
    "    ]\n",
    "    \n",
    "    return domain_string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by enzymes and merge with cluster map\n",
    "\n",
    "for enzyme in enzymes:\n",
    "    grouped_df_clean_subset = grouped_df_clean[grouped_df_clean['Enzyme'] == enzyme]\n",
    "    merged_df = pd.merge(grouped_df_clean_subset, cluster_map, left_on='Uniref', right_on='unclustered', how='left')\n",
    "    merged_df = merged_df.dropna(subset=['foldseek'])\n",
    "\n",
    "    if merged_df.shape[0] > 0:\n",
    "        grouped_merged_domain_cluster = merged_df.groupby('foldseek').agg({\n",
    "                'Domains': list,    # Aggregate Domains into a list\n",
    "                'Uniref': list,     # Aggregate Uniref into a list\n",
    "                'Enzyme': set       # Aggregate Enzyme into a set (to remove duplicates)\n",
    "            }).reset_index()\n",
    "        \n",
    "        grouped_merged_domain_cluster['member_count'] = grouped_merged_domain_cluster['Uniref'].apply(len)\n",
    "\n",
    "        grouped_merged_domain_cluster['Domains'] = grouped_merged_domain_cluster['Domains'].apply(\n",
    "            lambda x: clean_and_convert(x) if isinstance(x, list) else x)\n",
    "        \n",
    "        print(grouped_merged_domain_cluster.head())\n",
    "\n",
    "        grouped_merged_domain_cluster.to_csv(f\"/Volumes/PGH-Backup/domains/IPS/{enzyme}_IPS_results_grouped.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Network Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_domain_similarity(subset_df):\n",
    "\n",
    "    subset_df = pd.read_csv(subset_df, sep='\\t')\n",
    "    \n",
    "    # Initialize to track how many proteins have each domain in each cluster\n",
    "    domain_occurrences = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Iterate over the dataframe to count domain presence per protein\n",
    "    for index, row in subset_df.iterrows():\n",
    "        cluster_id = row['foldseek']\n",
    "        domains = row['Domains']\n",
    "\n",
    "        # Check if 'domains' is a valid non-empty list or string\n",
    "        if isinstance(domains, str) and domains.strip() != '':\n",
    "            try:\n",
    "                # Safely evaluate the string into a list\n",
    "                unique_domains = set(eval(domains))\n",
    "            except:\n",
    "                # Skip any domains that can't be evaluated\n",
    "                continue\n",
    "        elif isinstance(domains, (list, tuple, np.ndarray)) and len(domains) > 0:\n",
    "            unique_domains = set(domains)\n",
    "        else:\n",
    "            # Skip if 'domains' is None, NaN, empty, or not a valid type\n",
    "            continue\n",
    "\n",
    "        # Count each domain in the set\n",
    "        for domain in unique_domains:\n",
    "            domain_occurrences[cluster_id][domain] += 1\n",
    "\n",
    "    # Calculate the percentage of proteins with each domain in each cluster\n",
    "    domain_percentages = {}\n",
    "    for cluster, domains_dict in domain_occurrences.items():\n",
    "        member_count = subset_df.loc[subset_df['foldseek'] == cluster, 'member_count'].values[0]\n",
    "        domain_percentages[cluster] = {domain: count / member_count for domain, count in domains_dict.items()}\n",
    "\n",
    "    # Convert domain percentages to a matrix for similarity calculation\n",
    "    # Create a list of all unique domains across all clusters\n",
    "    all_domains = set(domain for cluster_domains in domain_percentages.values() for domain in cluster_domains.keys())\n",
    "\n",
    "    # Create a matrix of domain percentages for each cluster\n",
    "    cluster_ids = list(domain_percentages.keys())\n",
    "    domain_matrix = np.zeros((len(cluster_ids), len(all_domains)))\n",
    "\n",
    "    # Mapping of cluster IDs and domain indices to facilitate matrix population\n",
    "    cluster_idx_map = {cluster_id: idx for idx, cluster_id in enumerate(cluster_ids)}\n",
    "    domain_idx_map = {domain: idx for idx, domain in enumerate(all_domains)}\n",
    "\n",
    "    # Populate the matrix with domain percentages\n",
    "    for cluster_id, domains_dict in domain_percentages.items():\n",
    "        for domain, percentage in domains_dict.items():\n",
    "            cluster_idx = cluster_idx_map[cluster_id]\n",
    "            domain_idx = domain_idx_map[domain]\n",
    "            domain_matrix[cluster_idx, domain_idx] = percentage\n",
    "\n",
    "    # Calculate cosine similarity between clusters based on domain matrix\n",
    "    cosine_sim = cosine_similarity(domain_matrix)\n",
    "\n",
    "    # Convert the similarity matrix to edge list for significant similarities\n",
    "    # We consider a similarity significant if it's above 0.1 (can adjust)\n",
    "    significant_similarity_threshold = 0.8\n",
    "    significant_edges = []\n",
    "    for i in range(len(cluster_ids)):\n",
    "        for j in range(i+1, len(cluster_ids)):\n",
    "            if cosine_sim[i, j] > significant_similarity_threshold:\n",
    "                significant_edges.append((cluster_ids[i], cluster_ids[j], cosine_sim[i, j]))\n",
    "        \n",
    "    return significant_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network(enzyme_type, subset_df, significant_edges, association_table=None, title=None, global_min_size=None, global_max_size=None):\n",
    "    \"\"\" Plot the network graph for each unique enzyme type. Adjust node colors based on\n",
    "        the enzyme type and node sizes based on cluster sizes. \"\"\"\n",
    "    \n",
    "    subset_df = pd.read_csv(subset_df, sep='\\t')\n",
    "\n",
    "    # Create the network graph\n",
    "    G_adjusted_similarity = nx.Graph()\n",
    "\n",
    "    # Subset cluster_ids and edges based on the enzyme type in subset_df\n",
    "    cluster_ids_subset = subset_df['foldseek'].tolist()\n",
    "    edges_subset = [(u, v, w) for u, v, w in significant_edges if u in cluster_ids_subset and v in cluster_ids_subset]\n",
    "\n",
    "    # Add nodes (clusters) for the subset\n",
    "    G_adjusted_similarity.add_nodes_from(cluster_ids_subset)\n",
    "\n",
    "    # Add edges with weights based on cosine similarity for the subset\n",
    "    G_adjusted_similarity.add_weighted_edges_from(edges_subset)\n",
    "\n",
    "    # --- NEW: Get the connected components (subclusters) ---\n",
    "    connected_components = list(nx.connected_components(G_adjusted_similarity))\n",
    "\n",
    "    # Rank the connected components by their size (number of nodes)\n",
    "    connected_components_sorted = sorted(connected_components, key=len, reverse=True)\n",
    "\n",
    "    # Keep the top 5 largest clusters, color them, and set the rest to grey\n",
    "    top_n = 5\n",
    "    cmap = plt.get_cmap('tab10')  # Use a colormap with 10 distinct colors\n",
    "    cluster_colors = {i: cmap(i / top_n) for i in range(top_n)}  # Assign colors to top 5 clusters\n",
    "    grey_color = 'grey'\n",
    "\n",
    "    # Create a mapping of node to its subcluster color\n",
    "    node_color_map = {}\n",
    "    for i, component in enumerate(connected_components_sorted):\n",
    "        if i < top_n:\n",
    "            # Assign a color from the colormap to top 5 clusters\n",
    "            for node in component:\n",
    "                node_color_map[node] = cluster_colors[i]\n",
    "        else:\n",
    "            # Assign grey color to the remaining smaller clusters\n",
    "            for node in component:\n",
    "                node_color_map[node] = grey_color\n",
    "\n",
    "    # Get the cluster sizes from the 'member_count' column in the subset_df\n",
    "    cluster_sizes = subset_df.set_index('foldseek')['member_count'].to_dict()\n",
    "\n",
    "    # Normalize cluster sizes globally\n",
    "    if global_min_size is None:\n",
    "        global_min_size = min(cluster_sizes.values())\n",
    "    if global_max_size is None:\n",
    "        global_max_size = max(cluster_sizes.values())\n",
    "\n",
    "    min_size = 20\n",
    "    max_size = 1000\n",
    "    node_sizes = [\n",
    "        ((cluster_sizes[node] - global_min_size) / (global_max_size - global_min_size) * (max_size - min_size) + min_size)\n",
    "        if node in cluster_sizes else min_size\n",
    "        for node in G_adjusted_similarity.nodes()\n",
    "    ]\n",
    "\n",
    "    # --- NEW: Extract node colors based on cluster assignment ---\n",
    "    node_colors = [node_color_map[node] for node in G_adjusted_similarity.nodes()]\n",
    "\n",
    "    # Visualize the adjusted network for the enzyme type\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    pos = nx.spring_layout(G_adjusted_similarity, seed=42, k=0.5)  # Adjust the 'k' parameter to control node spacing\n",
    "\n",
    "    # Draw the network\n",
    "    nodes = nx.draw_networkx_nodes(G_adjusted_similarity, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G_adjusted_similarity, pos, alpha=0.5)\n",
    "    nx.draw_networkx_labels(G_adjusted_similarity, pos, font_size=5, alpha=0.7)\n",
    "\n",
    "    # --- NEW: Add title and legend ---\n",
    "    if title is not None:\n",
    "        plt.title(f\"{title} - {enzyme_type}\")\n",
    "    else:\n",
    "        plt.title(f\"Adjusted Network Graph for {enzyme_type}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # --- NEW: Add legend showing only top 5 clusters ---\n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {i+1}', \n",
    "                   markerfacecolor=cluster_colors[i], markersize=10)\n",
    "        for i in range(top_n)\n",
    "    ]\n",
    "    handles.append(plt.Line2D([0], [0], marker='o', color='w', label=f'Other Clusters', \n",
    "                   markerfacecolor=grey_color, markersize=10))\n",
    "    \n",
    "    plt.legend(handles=handles, title='Subclusters', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Save the plot for each enzyme type\n",
    "    plt.savefig(f'./{enzyme_type}_adjusted_network.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "    return G_adjusted_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_domains(subset_df, G_adjusted_similarity, top_n=5, top_domains=3):\n",
    "    subset_df = pd.read_csv(subset_df, sep='\\t')\n",
    "    \n",
    "    # Get the connected components (clusters)\n",
    "    connected_components = list(nx.connected_components(G_adjusted_similarity))\n",
    "    \n",
    "    # Sort the connected components by size (number of nodes) in descending order\n",
    "    connected_components_sorted = sorted(connected_components, key=len, reverse=True)\n",
    "    \n",
    "    # Limit to the top_n largest clusters\n",
    "    top_connected_components = connected_components_sorted[:top_n]\n",
    "\n",
    "    # Create a dictionary to store domains for each of the top_n clusters\n",
    "    cluster_domains = {}\n",
    "\n",
    "    for i, component in enumerate(top_connected_components):\n",
    "        cluster_name = f'Cluster_{i+1}'\n",
    "        domain_counter = Counter()  # Use a Counter to track domain frequencies\n",
    "        for node in component:\n",
    "            domains_str = subset_df.loc[subset_df['foldseek'] == node, 'Domains'].values[0]\n",
    "            try:\n",
    "                domains = eval(domains_str)  # Safely evaluate domain strings\n",
    "                domain_counter.update(domains)  # Count domain occurrences\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # Get the top N most common domains in the cluster\n",
    "        cluster_domains[cluster_name] = domain_counter.most_common(top_domains)\n",
    "\n",
    "    # Print and return the top 3 domains for each cluster\n",
    "    for cluster, top_domains in cluster_domains.items():\n",
    "        print(f\"Top {len(top_domains)} domains in {cluster}: {top_domains}\")\n",
    "\n",
    "    return cluster_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzymes = ['Amidase', 'DD-carboxypeptidase', 'DD-endopeptidase', 'DL-endopeptidase', \n",
    "           'Glucosaminidase', 'LD-carboxypeptidase', 'Muramidase']\n",
    "\n",
    "path = f'/Volumes/PGH-Backup/domains/IPS/clustered/{enzyme}_IPS_results_grouped.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this part of the code to pass in global min/max sizes across all enzymes\n",
    "global_min_size = float('inf')\n",
    "global_max_size = float('-inf')\n",
    "\n",
    "# Loop through each enzyme type and calculate global min/max cluster sizes first\n",
    "for enzyme in enzymes:\n",
    "    path = f'/Volumes/PGH-Backup/domains/IPS/clustered/{enzyme}_IPS_results_grouped.tsv'\n",
    "    \n",
    "    subset_df = pd.read_csv(path, sep='\\t')\n",
    "    cluster_sizes = subset_df['member_count'].values\n",
    "\n",
    "    global_min_size = min(global_min_size, min(cluster_sizes))\n",
    "    global_max_size = max(global_max_size, max(cluster_sizes))\n",
    "\n",
    "# Now, loop again to plot each enzyme network with consistent global node size scaling\n",
    "for enzyme in enzymes:\n",
    "    path = f'/Volumes/PGH-Backup/domains/IPS/clustered/{enzyme}_IPS_results_grouped.tsv'\n",
    "    \n",
    "    significant_edges = calculate_domain_similarity(path)\n",
    "\n",
    "    G_adjusted_similarity = plot_network(\n",
    "        enzyme_type=enzyme,\n",
    "        subset_df=path,\n",
    "        significant_edges=significant_edges,\n",
    "        title=None,\n",
    "        global_min_size=global_min_size,\n",
    "        global_max_size=global_max_size\n",
    "    )\n",
    "    \n",
    "    print(f\"Clusters for {enzyme}\")\n",
    "    cluster_domains = extract_top_domains(path, G_adjusted_similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Comparison with clustering methods, how different are domain inclusion stats between sequence clustering and structural?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: How do domain percentages change from sequence clustering to foldseek clustering?**\n",
    "1. merge domain table with cluster maps\n",
    "2. groupby mmseqs cluster reps\n",
    "3. clean formatting for domain lists\n",
    "4. calculate stats on % domain inclusion, do same for foldseek clusters\n",
    "5. visualizations to compare "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: merge domain table w cluster maps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amidase_UniRef100_A0A009ES59</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amidase_UniRef100_A0A009FUX6</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amidase_UniRef100_A0A009H4S4</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amidase_UniRef100_A0A009HT94</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amidase_UniRef100_A0A009L0R9</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707784</th>\n",
       "      <td>UC118_WP_253005939.1</td>\n",
       "      <td>['NlpC/P60 family', 'LysM domain', 'LysM domai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707785</th>\n",
       "      <td>UC118_WP_255820014.1</td>\n",
       "      <td>['LysM domain', 'LysM domain', 'LysM domain', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707786</th>\n",
       "      <td>UC118_WP_263296879.1</td>\n",
       "      <td>['NlpC/P60 family', 'LysM domain', 'LysM domai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707787</th>\n",
       "      <td>UC118_WP_263297069.1</td>\n",
       "      <td>['LysM domain', 'LysM domain', 'LysM domain', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707788</th>\n",
       "      <td>UC118_WP_263298109.1</td>\n",
       "      <td>['NlpC/P60 family', 'LysM domain', 'LysM domai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707789 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0  \\\n",
       "0       Amidase_UniRef100_A0A009ES59   \n",
       "1       Amidase_UniRef100_A0A009FUX6   \n",
       "2       Amidase_UniRef100_A0A009H4S4   \n",
       "3       Amidase_UniRef100_A0A009HT94   \n",
       "4       Amidase_UniRef100_A0A009L0R9   \n",
       "...                              ...   \n",
       "707784          UC118_WP_253005939.1   \n",
       "707785          UC118_WP_255820014.1   \n",
       "707786          UC118_WP_263296879.1   \n",
       "707787          UC118_WP_263297069.1   \n",
       "707788          UC118_WP_263298109.1   \n",
       "\n",
       "                                                        1  \n",
       "0                  ['N-acetylmuramoyl-L-alanine amidase']  \n",
       "1                  ['N-acetylmuramoyl-L-alanine amidase']  \n",
       "2                  ['N-acetylmuramoyl-L-alanine amidase']  \n",
       "3                  ['N-acetylmuramoyl-L-alanine amidase']  \n",
       "4                  ['N-acetylmuramoyl-L-alanine amidase']  \n",
       "...                                                   ...  \n",
       "707784  ['NlpC/P60 family', 'LysM domain', 'LysM domai...  \n",
       "707785  ['LysM domain', 'LysM domain', 'LysM domain', ...  \n",
       "707786  ['NlpC/P60 family', 'LysM domain', 'LysM domai...  \n",
       "707787  ['LysM domain', 'LysM domain', 'LysM domain', ...  \n",
       "707788  ['NlpC/P60 family', 'LysM domain', 'LysM domai...  \n",
       "\n",
       "[707789 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grouped_df_clean = pd.read_csv(\"E:/domains/IPS/clustered/all_IPS_results_grouped.tsv\", sep='\\t', header=None)\n",
    "\n",
    "# mac\n",
    "grouped_df_clean = pd.read_csv(\"/Volumes/PGH-Backup/domains/IPS/clustered/all_IPS_results_grouped.tsv\", sep='\\t', header=None)\n",
    "\n",
    "display(grouped_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullIdentifier</th>\n",
       "      <th>Domains</th>\n",
       "      <th>Uniref</th>\n",
       "      <th>Enzyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amidase_UniRef100_A0A009ES59</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "      <td>A0A009ES59</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amidase_UniRef100_A0A009FUX6</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "      <td>A0A009FUX6</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amidase_UniRef100_A0A009H4S4</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "      <td>A0A009H4S4</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amidase_UniRef100_A0A009HT94</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "      <td>A0A009HT94</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amidase_UniRef100_A0A009L0R9</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "      <td>A0A009L0R9</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707784</th>\n",
       "      <td>UC118_WP_253005939.1</td>\n",
       "      <td>['NlpC/P60 family', 'LysM domain', 'LysM domai...</td>\n",
       "      <td>253005939.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707785</th>\n",
       "      <td>UC118_WP_255820014.1</td>\n",
       "      <td>['LysM domain', 'LysM domain', 'LysM domain', ...</td>\n",
       "      <td>255820014.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707786</th>\n",
       "      <td>UC118_WP_263296879.1</td>\n",
       "      <td>['NlpC/P60 family', 'LysM domain', 'LysM domai...</td>\n",
       "      <td>263296879.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707787</th>\n",
       "      <td>UC118_WP_263297069.1</td>\n",
       "      <td>['LysM domain', 'LysM domain', 'LysM domain', ...</td>\n",
       "      <td>263297069.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707788</th>\n",
       "      <td>UC118_WP_263298109.1</td>\n",
       "      <td>['NlpC/P60 family', 'LysM domain', 'LysM domai...</td>\n",
       "      <td>263298109.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682410 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      FullIdentifier  \\\n",
       "0       Amidase_UniRef100_A0A009ES59   \n",
       "1       Amidase_UniRef100_A0A009FUX6   \n",
       "2       Amidase_UniRef100_A0A009H4S4   \n",
       "3       Amidase_UniRef100_A0A009HT94   \n",
       "4       Amidase_UniRef100_A0A009L0R9   \n",
       "...                              ...   \n",
       "707784          UC118_WP_253005939.1   \n",
       "707785          UC118_WP_255820014.1   \n",
       "707786          UC118_WP_263296879.1   \n",
       "707787          UC118_WP_263297069.1   \n",
       "707788          UC118_WP_263298109.1   \n",
       "\n",
       "                                                  Domains       Uniref  \\\n",
       "0                  ['N-acetylmuramoyl-L-alanine amidase']   A0A009ES59   \n",
       "1                  ['N-acetylmuramoyl-L-alanine amidase']   A0A009FUX6   \n",
       "2                  ['N-acetylmuramoyl-L-alanine amidase']   A0A009H4S4   \n",
       "3                  ['N-acetylmuramoyl-L-alanine amidase']   A0A009HT94   \n",
       "4                  ['N-acetylmuramoyl-L-alanine amidase']   A0A009L0R9   \n",
       "...                                                   ...          ...   \n",
       "707784  ['NlpC/P60 family', 'LysM domain', 'LysM domai...  253005939.1   \n",
       "707785  ['LysM domain', 'LysM domain', 'LysM domain', ...  255820014.1   \n",
       "707786  ['NlpC/P60 family', 'LysM domain', 'LysM domai...  263296879.1   \n",
       "707787  ['LysM domain', 'LysM domain', 'LysM domain', ...  263297069.1   \n",
       "707788  ['NlpC/P60 family', 'LysM domain', 'LysM domai...  263298109.1   \n",
       "\n",
       "         Enzyme  \n",
       "0       Amidase  \n",
       "1       Amidase  \n",
       "2       Amidase  \n",
       "3       Amidase  \n",
       "4       Amidase  \n",
       "...         ...  \n",
       "707784    UC118  \n",
       "707785    UC118  \n",
       "707786    UC118  \n",
       "707787    UC118  \n",
       "707788    UC118  \n",
       "\n",
       "[682410 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_grouped_df_clean, enzymes = format_domain_table(grouped_df_clean)\n",
    "\n",
    "display(new_grouped_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grouped_df_clean['Domains'] = new_grouped_df_clean['Domains'].apply(\n",
    "            lambda x: clean_and_convert(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unqiue elements in a list. If they appear multiple times, adjust the string to reflect that\n",
    "\n",
    "def find_unique_elements(lst):\n",
    "    \"\"\"\n",
    "    Function to find unique elements in a list. If they appear multiple times, adjust the string to reflect that.\n",
    "    \"\"\"\n",
    "    \n",
    "    element_counts = Counter(lst)\n",
    "    adjusted_elements = []\n",
    "    \n",
    "    for element in lst:\n",
    "        if element_counts[element] > 1:\n",
    "            adjusted_elements.append(f\"{element} ({element_counts[element]})\")\n",
    "        else:\n",
    "            adjusted_elements.append(element)\n",
    "\n",
    "    adjusted_elements = list(set(adjusted_elements))\n",
    "    \n",
    "    return adjusted_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullIdentifier</th>\n",
       "      <th>Domains</th>\n",
       "      <th>Uniref</th>\n",
       "      <th>Enzyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amidase_UniRef100_A0A009ES59</td>\n",
       "      <td>[l (3), m (3), t, ' (2), y (2), L, i (2), ], d...</td>\n",
       "      <td>A0A009ES59</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amidase_UniRef100_A0A009FUX6</td>\n",
       "      <td>[l (3), m (3), t, ' (2), y (2), L, i (2), ], d...</td>\n",
       "      <td>A0A009FUX6</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amidase_UniRef100_A0A009H4S4</td>\n",
       "      <td>[l (3), m (3), t, ' (2), y (2), L, i (2), ], d...</td>\n",
       "      <td>A0A009H4S4</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amidase_UniRef100_A0A009HT94</td>\n",
       "      <td>[l (3), m (3), t, ' (2), y (2), L, i (2), ], d...</td>\n",
       "      <td>A0A009HT94</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amidase_UniRef100_A0A009L0R9</td>\n",
       "      <td>[l (3), m (3), t, ' (2), y (2), L, i (2), ], d...</td>\n",
       "      <td>A0A009L0R9</td>\n",
       "      <td>Amidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707784</th>\n",
       "      <td>UC118_WP_253005939.1</td>\n",
       "      <td>[f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...</td>\n",
       "      <td>253005939.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707785</th>\n",
       "      <td>UC118_WP_255820014.1</td>\n",
       "      <td>[f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...</td>\n",
       "      <td>255820014.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707786</th>\n",
       "      <td>UC118_WP_263296879.1</td>\n",
       "      <td>[f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...</td>\n",
       "      <td>263296879.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707787</th>\n",
       "      <td>UC118_WP_263297069.1</td>\n",
       "      <td>[f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...</td>\n",
       "      <td>263297069.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707788</th>\n",
       "      <td>UC118_WP_263298109.1</td>\n",
       "      <td>[f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...</td>\n",
       "      <td>263298109.1</td>\n",
       "      <td>UC118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682410 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      FullIdentifier  \\\n",
       "0       Amidase_UniRef100_A0A009ES59   \n",
       "1       Amidase_UniRef100_A0A009FUX6   \n",
       "2       Amidase_UniRef100_A0A009H4S4   \n",
       "3       Amidase_UniRef100_A0A009HT94   \n",
       "4       Amidase_UniRef100_A0A009L0R9   \n",
       "...                              ...   \n",
       "707784          UC118_WP_253005939.1   \n",
       "707785          UC118_WP_255820014.1   \n",
       "707786          UC118_WP_263296879.1   \n",
       "707787          UC118_WP_263297069.1   \n",
       "707788          UC118_WP_263298109.1   \n",
       "\n",
       "                                                  Domains       Uniref  \\\n",
       "0       [l (3), m (3), t, ' (2), y (2), L, i (2), ], d...   A0A009ES59   \n",
       "1       [l (3), m (3), t, ' (2), y (2), L, i (2), ], d...   A0A009FUX6   \n",
       "2       [l (3), m (3), t, ' (2), y (2), L, i (2), ], d...   A0A009H4S4   \n",
       "3       [l (3), m (3), t, ' (2), y (2), L, i (2), ], d...   A0A009HT94   \n",
       "4       [l (3), m (3), t, ' (2), y (2), L, i (2), ], d...   A0A009L0R9   \n",
       "...                                                   ...          ...   \n",
       "707784  [f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...  253005939.1   \n",
       "707785  [f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...  255820014.1   \n",
       "707786  [f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...  263296879.1   \n",
       "707787  [f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...  263297069.1   \n",
       "707788  [f, L (3), 6, d (3), m (4), ' (8), a (4), M (3...  263298109.1   \n",
       "\n",
       "         Enzyme  \n",
       "0       Amidase  \n",
       "1       Amidase  \n",
       "2       Amidase  \n",
       "3       Amidase  \n",
       "4       Amidase  \n",
       "...         ...  \n",
       "707784    UC118  \n",
       "707785    UC118  \n",
       "707786    UC118  \n",
       "707787    UC118  \n",
       "707788    UC118  \n",
       "\n",
       "[682410 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_grouped_df_clean['Domains'] = new_grouped_df_clean['Domains'].apply(find_unique_elements)\n",
    "\n",
    "display(new_grouped_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unclustered</th>\n",
       "      <th>mmseqs</th>\n",
       "      <th>foldseek</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A432IFZ8</td>\n",
       "      <td>A0A432IFZ8</td>\n",
       "      <td>A0A534TJ56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A369Y4I6</td>\n",
       "      <td>A0A432IFZ8</td>\n",
       "      <td>A0A534TJ56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3HA38</td>\n",
       "      <td>A0A432IFZ8</td>\n",
       "      <td>A0A534TJ56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UPI0004050AE8</td>\n",
       "      <td>A0A369PUK8</td>\n",
       "      <td>A0A455SSC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A924USN5</td>\n",
       "      <td>A0A369PUK8</td>\n",
       "      <td>A0A455SSC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331605</th>\n",
       "      <td>R5VGU4</td>\n",
       "      <td>R5VGU4</td>\n",
       "      <td>R5VGU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331606</th>\n",
       "      <td>T0DIM4</td>\n",
       "      <td>T0DIM4</td>\n",
       "      <td>A0A5N7MBX0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331607</th>\n",
       "      <td>UPI000EA3697F</td>\n",
       "      <td>T0DIM4</td>\n",
       "      <td>A0A5N7MBX0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331608</th>\n",
       "      <td>A0A2S3QPZ4</td>\n",
       "      <td>T0DIM4</td>\n",
       "      <td>A0A5N7MBX0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331609</th>\n",
       "      <td>A0A4Z0KUE1</td>\n",
       "      <td>T0DIM4</td>\n",
       "      <td>A0A5N7MBX0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>703043 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          unclustered      mmseqs    foldseek\n",
       "0                                            \n",
       "0          A0A432IFZ8  A0A432IFZ8  A0A534TJ56\n",
       "1          A0A369Y4I6  A0A432IFZ8  A0A534TJ56\n",
       "2              E3HA38  A0A432IFZ8  A0A534TJ56\n",
       "3       UPI0004050AE8  A0A369PUK8  A0A455SSC1\n",
       "4          A0A924USN5  A0A369PUK8  A0A455SSC1\n",
       "...               ...         ...         ...\n",
       "331605         R5VGU4      R5VGU4      R5VGU4\n",
       "331606         T0DIM4      T0DIM4  A0A5N7MBX0\n",
       "331607  UPI000EA3697F      T0DIM4  A0A5N7MBX0\n",
       "331608     A0A2S3QPZ4      T0DIM4  A0A5N7MBX0\n",
       "331609     A0A4Z0KUE1      T0DIM4  A0A5N7MBX0\n",
       "\n",
       "[703043 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cluster_map = pd.read_csv(\"E:/clustering/newest_cluster_maps/catted_maps.tsv\", sep='\\t', index_col=0, header=None)\n",
    "\n",
    "# mac\n",
    "cluster_map = pd.read_csv(\"/Volumes/PGH-Backup/clustering/newest_cluster_maps/catted_maps.tsv\", sep='\\t', index_col=0, header=None)\n",
    "\n",
    "clean_cluster_map = format_cluster_map(cluster_map)\n",
    "\n",
    "display(clean_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop foldseek column\n",
    "clean_cluster_map.drop(columns=['foldseek'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amidase' 'DD-carboxypeptidase' 'DD-endopeptidase' 'DL-endopeptidase'\n",
      " 'Diadenylate' 'Glucosaminidase' 'LD-carboxypeptidase' 'LD-endopeptidase'\n",
      " 'Muramidase' 'SagA' 'UC118']\n"
     ]
    }
   ],
   "source": [
    "print(enzymes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps 2 & 3: group by mmseqs & format domain info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for enzyme in enzymes:\n",
    "    grouped_df_clean_subset = new_grouped_df_clean[new_grouped_df_clean['Enzyme'] == enzyme]\n",
    "    merged_df = pd.merge(grouped_df_clean_subset, cluster_map, left_on='Uniref', right_on='unclustered', how='left')\n",
    "    merged_df = merged_df.dropna(subset=['mmseqs'])\n",
    "\n",
    "    if merged_df.shape[0] > 0:\n",
    "        grouped_merged_domain_cluster = merged_df.groupby('mmseqs').agg({\n",
    "                'Domains': list,    # Aggregate Domains into a list\n",
    "                'Uniref': list,     # Aggregate Uniref into a list\n",
    "                'Enzyme': set       # Aggregate Enzyme into a set (to remove duplicates)\n",
    "            }).reset_index()\n",
    "        \n",
    "        grouped_merged_domain_cluster['member_count'] = grouped_merged_domain_cluster['Uniref'].apply(len)\n",
    "\n",
    "        grouped_merged_domain_cluster['Domains'] = grouped_merged_domain_cluster['Domains'].apply(\n",
    "            lambda x: clean_and_convert(x) if isinstance(x, list) else x)\n",
    "        \n",
    "        print(grouped_merged_domain_cluster.head())\n",
    "\n",
    "        grouped_merged_domain_cluster.to_csv(f\"/Volumes/PGH-Backup/domains/IPS/{enzyme}_IPS_results_grouped_mmseqs.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Calculate stats for domain inclusion for mmseqs clusters compared to foldseek**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmseqs</th>\n",
       "      <th>Domains</th>\n",
       "      <th>Uniref</th>\n",
       "      <th>Enzyme</th>\n",
       "      <th>member_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A010NMG8</td>\n",
       "      <td>['ell wall binding domain 2 (CWB2)', 'ell wall...</td>\n",
       "      <td>['A0A010NMG8', 'A0A010PUG6', 'A0A233V2K4', 'A0...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A010PSL2</td>\n",
       "      <td>['Cysteine-rich secretory protein family', 'el...</td>\n",
       "      <td>['A0A010PSL2', 'A0A233VWJ9', 'A0A6I2SEB3', 'B0...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A010YT92</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase', 'N-acet...</td>\n",
       "      <td>['A0A010YT92', 'UPI000240E03A', 'UPI0004BCB526...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A010ZI67</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase', 'N-acet...</td>\n",
       "      <td>['A0A010ZI67', 'A0A7X7BLJ5', 'A0A7X9T7G7', 'A0...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A011Q2X5</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase', 'N-acet...</td>\n",
       "      <td>['A0A011Q2X5', 'A0A963P6Q4', 'W7WK78']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23115</th>\n",
       "      <td>X8ECC6</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase']</td>\n",
       "      <td>['X8ECC6']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23116</th>\n",
       "      <td>X8HN28</td>\n",
       "      <td>['Choline-binding repeat', 'Choline-binding re...</td>\n",
       "      <td>['UPI0004B1C17B', 'X8HN28']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23117</th>\n",
       "      <td>X8ISN4</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase', 'N-acet...</td>\n",
       "      <td>['A0A7Y8VSE7', 'X8ISN4']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23118</th>\n",
       "      <td>Z4WVM5</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase', 'N-acet...</td>\n",
       "      <td>['A0A069ZJT9', 'A0A076ILX0', 'A0A0A2DYZ4', 'A0...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23119</th>\n",
       "      <td>Z9JM41</td>\n",
       "      <td>['N-acetylmuramoyl-L-alanine amidase', 'N-acet...</td>\n",
       "      <td>['UPI0013B3D01E', 'Z9JM41']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mmseqs                                            Domains  \\\n",
       "0      A0A010NMG8  ['ell wall binding domain 2 (CWB2)', 'ell wall...   \n",
       "1      A0A010PSL2  ['Cysteine-rich secretory protein family', 'el...   \n",
       "2      A0A010YT92  ['N-acetylmuramoyl-L-alanine amidase', 'N-acet...   \n",
       "3      A0A010ZI67  ['N-acetylmuramoyl-L-alanine amidase', 'N-acet...   \n",
       "4      A0A011Q2X5  ['N-acetylmuramoyl-L-alanine amidase', 'N-acet...   \n",
       "...           ...                                                ...   \n",
       "23115      X8ECC6             ['N-acetylmuramoyl-L-alanine amidase']   \n",
       "23116      X8HN28  ['Choline-binding repeat', 'Choline-binding re...   \n",
       "23117      X8ISN4  ['N-acetylmuramoyl-L-alanine amidase', 'N-acet...   \n",
       "23118      Z4WVM5  ['N-acetylmuramoyl-L-alanine amidase', 'N-acet...   \n",
       "23119      Z9JM41  ['N-acetylmuramoyl-L-alanine amidase', 'N-acet...   \n",
       "\n",
       "                                                  Uniref       Enzyme  \\\n",
       "0      ['A0A010NMG8', 'A0A010PUG6', 'A0A233V2K4', 'A0...  {'Amidase'}   \n",
       "1      ['A0A010PSL2', 'A0A233VWJ9', 'A0A6I2SEB3', 'B0...  {'Amidase'}   \n",
       "2      ['A0A010YT92', 'UPI000240E03A', 'UPI0004BCB526...  {'Amidase'}   \n",
       "3      ['A0A010ZI67', 'A0A7X7BLJ5', 'A0A7X9T7G7', 'A0...  {'Amidase'}   \n",
       "4                 ['A0A011Q2X5', 'A0A963P6Q4', 'W7WK78']  {'Amidase'}   \n",
       "...                                                  ...          ...   \n",
       "23115                                         ['X8ECC6']  {'Amidase'}   \n",
       "23116                        ['UPI0004B1C17B', 'X8HN28']  {'Amidase'}   \n",
       "23117                           ['A0A7Y8VSE7', 'X8ISN4']  {'Amidase'}   \n",
       "23118  ['A0A069ZJT9', 'A0A076ILX0', 'A0A0A2DYZ4', 'A0...  {'Amidase'}   \n",
       "23119                        ['UPI0013B3D01E', 'Z9JM41']  {'Amidase'}   \n",
       "\n",
       "       member_count  \n",
       "0                17  \n",
       "1                 4  \n",
       "2                 4  \n",
       "3                 7  \n",
       "4                 3  \n",
       "...             ...  \n",
       "23115             1  \n",
       "23116             2  \n",
       "23117             2  \n",
       "23118           207  \n",
       "23119             2  \n",
       "\n",
       "[23120 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_view = pd.read_csv(\"/Volumes/PGH-Backup/domains/IPS/mmseqs_groups/Amidase_IPS_results_grouped_mmseqs.tsv\", sep='\\t')\n",
    "\n",
    "display(test_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n",
      "/var/folders/sm/rgfxp6g94f18340p2rvqnsc00000gn/T/ipykernel_46693/3756757220.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_view[domain] = 0.0  # Initialize the column with 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmseqs</th>\n",
       "      <th>Domains</th>\n",
       "      <th>Uniref</th>\n",
       "      <th>Enzyme</th>\n",
       "      <th>member_count</th>\n",
       "      <th>Family of unknown function (DUF5633)</th>\n",
       "      <th>ell wall binding domain 2 (CWB2)</th>\n",
       "      <th>Cysteine-rich secretory protein family</th>\n",
       "      <th>Mannosyl-glycoprotein endo-beta-N-acetylglucosaminidase</th>\n",
       "      <th>N-acetylmuramoyl-L-alanine amidase</th>\n",
       "      <th>...</th>\n",
       "      <th>Domain of unknown function (DUF4280)</th>\n",
       "      <th>Domain of unknown function (DUF4347)</th>\n",
       "      <th>5'-nucleotidase, C-terminal domain</th>\n",
       "      <th>GTP-binding GTPase Middle Region</th>\n",
       "      <th>Family of unknown function (DUF6541)</th>\n",
       "      <th>Glycosyl hydrolase family 46</th>\n",
       "      <th>Phage lysozyme</th>\n",
       "      <th>Terminase RNaseH-like domain</th>\n",
       "      <th>Domain of unknown function (DUF4062)</th>\n",
       "      <th>NACHT domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A010NMG8</td>\n",
       "      <td>[ell wall binding domain 2 (CWB2), ell wall bi...</td>\n",
       "      <td>['A0A010NMG8', 'A0A010PUG6', 'A0A233V2K4', 'A0...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A010PSL2</td>\n",
       "      <td>[Cysteine-rich secretory protein family, ell w...</td>\n",
       "      <td>['A0A010PSL2', 'A0A233VWJ9', 'A0A6I2SEB3', 'B0...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A010YT92</td>\n",
       "      <td>[N-acetylmuramoyl-L-alanine amidase, N-acetylm...</td>\n",
       "      <td>['A0A010YT92', 'UPI000240E03A', 'UPI0004BCB526...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A010ZI67</td>\n",
       "      <td>[N-acetylmuramoyl-L-alanine amidase, N-acetylm...</td>\n",
       "      <td>['A0A010ZI67', 'A0A7X7BLJ5', 'A0A7X9T7G7', 'A0...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A011Q2X5</td>\n",
       "      <td>[N-acetylmuramoyl-L-alanine amidase, N-acetylm...</td>\n",
       "      <td>['A0A011Q2X5', 'A0A963P6Q4', 'W7WK78']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23115</th>\n",
       "      <td>X8ECC6</td>\n",
       "      <td>[N-acetylmuramoyl-L-alanine amidase]</td>\n",
       "      <td>['X8ECC6']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23116</th>\n",
       "      <td>X8HN28</td>\n",
       "      <td>[Choline-binding repeat, Choline-binding repea...</td>\n",
       "      <td>['UPI0004B1C17B', 'X8HN28']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23117</th>\n",
       "      <td>X8ISN4</td>\n",
       "      <td>[N-acetylmuramoyl-L-alanine amidase, N-acetylm...</td>\n",
       "      <td>['A0A7Y8VSE7', 'X8ISN4']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23118</th>\n",
       "      <td>Z4WVM5</td>\n",
       "      <td>[N-acetylmuramoyl-L-alanine amidase, N-acetylm...</td>\n",
       "      <td>['A0A069ZJT9', 'A0A076ILX0', 'A0A0A2DYZ4', 'A0...</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23119</th>\n",
       "      <td>Z9JM41</td>\n",
       "      <td>[N-acetylmuramoyl-L-alanine amidase, N-acetylm...</td>\n",
       "      <td>['UPI0013B3D01E', 'Z9JM41']</td>\n",
       "      <td>{'Amidase'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23120 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mmseqs                                            Domains  \\\n",
       "0      A0A010NMG8  [ell wall binding domain 2 (CWB2), ell wall bi...   \n",
       "1      A0A010PSL2  [Cysteine-rich secretory protein family, ell w...   \n",
       "2      A0A010YT92  [N-acetylmuramoyl-L-alanine amidase, N-acetylm...   \n",
       "3      A0A010ZI67  [N-acetylmuramoyl-L-alanine amidase, N-acetylm...   \n",
       "4      A0A011Q2X5  [N-acetylmuramoyl-L-alanine amidase, N-acetylm...   \n",
       "...           ...                                                ...   \n",
       "23115      X8ECC6               [N-acetylmuramoyl-L-alanine amidase]   \n",
       "23116      X8HN28  [Choline-binding repeat, Choline-binding repea...   \n",
       "23117      X8ISN4  [N-acetylmuramoyl-L-alanine amidase, N-acetylm...   \n",
       "23118      Z4WVM5  [N-acetylmuramoyl-L-alanine amidase, N-acetylm...   \n",
       "23119      Z9JM41  [N-acetylmuramoyl-L-alanine amidase, N-acetylm...   \n",
       "\n",
       "                                                  Uniref       Enzyme  \\\n",
       "0      ['A0A010NMG8', 'A0A010PUG6', 'A0A233V2K4', 'A0...  {'Amidase'}   \n",
       "1      ['A0A010PSL2', 'A0A233VWJ9', 'A0A6I2SEB3', 'B0...  {'Amidase'}   \n",
       "2      ['A0A010YT92', 'UPI000240E03A', 'UPI0004BCB526...  {'Amidase'}   \n",
       "3      ['A0A010ZI67', 'A0A7X7BLJ5', 'A0A7X9T7G7', 'A0...  {'Amidase'}   \n",
       "4                 ['A0A011Q2X5', 'A0A963P6Q4', 'W7WK78']  {'Amidase'}   \n",
       "...                                                  ...          ...   \n",
       "23115                                         ['X8ECC6']  {'Amidase'}   \n",
       "23116                        ['UPI0004B1C17B', 'X8HN28']  {'Amidase'}   \n",
       "23117                           ['A0A7Y8VSE7', 'X8ISN4']  {'Amidase'}   \n",
       "23118  ['A0A069ZJT9', 'A0A076ILX0', 'A0A0A2DYZ4', 'A0...  {'Amidase'}   \n",
       "23119                        ['UPI0013B3D01E', 'Z9JM41']  {'Amidase'}   \n",
       "\n",
       "       member_count  Family of unknown function (DUF5633)  \\\n",
       "0                17                              0.058824   \n",
       "1                 4                              0.000000   \n",
       "2                 4                              0.000000   \n",
       "3                 7                              0.000000   \n",
       "4                 3                              0.000000   \n",
       "...             ...                                   ...   \n",
       "23115             1                              0.000000   \n",
       "23116             2                              0.000000   \n",
       "23117             2                              0.000000   \n",
       "23118           207                              0.000000   \n",
       "23119             2                              0.000000   \n",
       "\n",
       "       ell wall binding domain 2 (CWB2)  \\\n",
       "0                                   3.0   \n",
       "1                                   3.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "...                                 ...   \n",
       "23115                               0.0   \n",
       "23116                               0.0   \n",
       "23117                               0.0   \n",
       "23118                               0.0   \n",
       "23119                               0.0   \n",
       "\n",
       "       Cysteine-rich secretory protein family  \\\n",
       "0                                    0.882353   \n",
       "1                                    1.000000   \n",
       "2                                    0.000000   \n",
       "3                                    0.000000   \n",
       "4                                    0.000000   \n",
       "...                                       ...   \n",
       "23115                                0.000000   \n",
       "23116                                0.000000   \n",
       "23117                                0.000000   \n",
       "23118                                0.000000   \n",
       "23119                                0.000000   \n",
       "\n",
       "       Mannosyl-glycoprotein endo-beta-N-acetylglucosaminidase  \\\n",
       "0                                                   0.00         \n",
       "1                                                   0.00         \n",
       "2                                                   0.25         \n",
       "3                                                   0.00         \n",
       "4                                                   0.00         \n",
       "...                                                  ...         \n",
       "23115                                               0.00         \n",
       "23116                                               1.00         \n",
       "23117                                               0.00         \n",
       "23118                                               0.00         \n",
       "23119                                               0.00         \n",
       "\n",
       "       N-acetylmuramoyl-L-alanine amidase  ...  \\\n",
       "0                                     0.0  ...   \n",
       "1                                     0.0  ...   \n",
       "2                                     1.0  ...   \n",
       "3                                     1.0  ...   \n",
       "4                                     1.0  ...   \n",
       "...                                   ...  ...   \n",
       "23115                                 1.0  ...   \n",
       "23116                                 1.0  ...   \n",
       "23117                                 1.0  ...   \n",
       "23118                                 1.0  ...   \n",
       "23119                                 1.0  ...   \n",
       "\n",
       "       Domain of unknown function (DUF4280)  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "23115                                   0.0   \n",
       "23116                                   0.0   \n",
       "23117                                   0.0   \n",
       "23118                                   0.0   \n",
       "23119                                   0.0   \n",
       "\n",
       "       Domain of unknown function (DUF4347)  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "23115                                   0.0   \n",
       "23116                                   0.0   \n",
       "23117                                   0.0   \n",
       "23118                                   0.0   \n",
       "23119                                   0.0   \n",
       "\n",
       "       5'-nucleotidase, C-terminal domain  GTP-binding GTPase Middle Region  \\\n",
       "0                                     0.0                               0.0   \n",
       "1                                     0.0                               0.0   \n",
       "2                                     0.0                               0.0   \n",
       "3                                     0.0                               0.0   \n",
       "4                                     0.0                               0.0   \n",
       "...                                   ...                               ...   \n",
       "23115                                 0.0                               0.0   \n",
       "23116                                 0.0                               0.0   \n",
       "23117                                 0.0                               0.0   \n",
       "23118                                 0.0                               0.0   \n",
       "23119                                 0.0                               0.0   \n",
       "\n",
       "       Family of unknown function (DUF6541)  Glycosyl hydrolase family 46  \\\n",
       "0                                       0.0                           0.0   \n",
       "1                                       0.0                           0.0   \n",
       "2                                       0.0                           0.0   \n",
       "3                                       0.0                           0.0   \n",
       "4                                       0.0                           0.0   \n",
       "...                                     ...                           ...   \n",
       "23115                                   0.0                           0.0   \n",
       "23116                                   0.0                           0.0   \n",
       "23117                                   0.0                           0.0   \n",
       "23118                                   0.0                           0.0   \n",
       "23119                                   0.0                           0.0   \n",
       "\n",
       "       Phage lysozyme  Terminase RNaseH-like domain  \\\n",
       "0                 0.0                           0.0   \n",
       "1                 0.0                           0.0   \n",
       "2                 0.0                           0.0   \n",
       "3                 0.0                           0.0   \n",
       "4                 0.0                           0.0   \n",
       "...               ...                           ...   \n",
       "23115             0.0                           0.0   \n",
       "23116             0.0                           0.0   \n",
       "23117             0.0                           0.0   \n",
       "23118             0.0                           0.0   \n",
       "23119             0.0                           0.0   \n",
       "\n",
       "       Domain of unknown function (DUF4062)  NACHT domain  \n",
       "0                                       0.0           0.0  \n",
       "1                                       0.0           0.0  \n",
       "2                                       0.0           0.0  \n",
       "3                                       0.0           0.0  \n",
       "4                                       0.0           0.0  \n",
       "...                                     ...           ...  \n",
       "23115                                   0.0           0.0  \n",
       "23116                                   0.0           0.0  \n",
       "23117                                   0.0           0.0  \n",
       "23118                                   0.0           0.0  \n",
       "23119                                   0.0           0.0  \n",
       "\n",
       "[23120 rows x 315 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_view['Domains'] = test_view['Domains'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Now proceed with your logic\n",
    "for idx, row in test_view.iterrows():\n",
    "    unique_domains = set(row['Domains'])  # Get unique domains from each row\n",
    "\n",
    "    # For each unique domain in the row\n",
    "    for domain in unique_domains:\n",
    "        if domain not in test_view.columns:  # If the domain is not already a column\n",
    "            test_view[domain] = 0.0  # Initialize the column with 0\n",
    "\n",
    "        # Fill the column with the proportion of the domain in the current row\n",
    "        test_view.at[idx, domain] = row['Domains'].count(domain) / row['member_count']\n",
    "\n",
    "# Display the updated dataframe\n",
    "display(test_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the average frequency of domain inclusion in each cluster?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
